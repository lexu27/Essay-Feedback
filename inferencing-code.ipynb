{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37afce14",
   "metadata": {
    "id": "fFN1KR2XFZI8",
    "papermill": {
     "duration": 0.01049,
     "end_time": "2022-11-27T01:27:16.625453",
     "exception": false,
     "start_time": "2022-11-27T01:27:16.614963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2099ebc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:16.662758Z",
     "iopub.status.busy": "2022-11-27T01:27:16.661526Z",
     "iopub.status.idle": "2022-11-27T01:27:24.707917Z",
     "shell.execute_reply": "2022-11-27T01:27:24.706833Z"
    },
    "papermill": {
     "duration": 8.067836,
     "end_time": "2022-11-27T01:27:24.711690",
     "exception": false,
     "start_time": "2022-11-27T01:27:16.643854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/transformers-422/transformers-4.24.0-py3-none-any.whl\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.20.1\r\n",
      "    Uninstalling transformers-4.20.1:\r\n",
      "      Successfully uninstalled transformers-4.20.1\r\n",
      "Successfully installed transformers-4.24.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall --no-deps --no-index /kaggle/input/transformers-422/transformers-4.24.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6daca41a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:24.739671Z",
     "iopub.status.busy": "2022-11-27T01:27:24.739129Z",
     "iopub.status.idle": "2022-11-27T01:27:32.673928Z",
     "shell.execute_reply": "2022-11-27T01:27:32.672715Z"
    },
    "id": "A4OW0qKyjzzY",
    "papermill": {
     "duration": 7.951388,
     "end_time": "2022-11-27T01:27:32.676640",
     "exception": false,
     "start_time": "2022-11-27T01:27:24.725252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pickle\n",
    "import transformers\n",
    "import os\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import glob\n",
    "import os\n",
    "import wandb\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import AdamW\n",
    "from text_unidecode import unidecode\n",
    "import torch\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "import re\n",
    "from torch.nn import Module\n",
    "import torch.nn as nn\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import gc\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4bdfaba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:32.696512Z",
     "iopub.status.busy": "2022-11-27T01:27:32.695474Z",
     "iopub.status.idle": "2022-11-27T01:27:32.704396Z",
     "shell.execute_reply": "2022-11-27T01:27:32.703372Z"
    },
    "papermill": {
     "duration": 0.0217,
     "end_time": "2022-11-27T01:27:32.706714",
     "exception": false,
     "start_time": "2022-11-27T01:27:32.685014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.24.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07565c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:32.724252Z",
     "iopub.status.busy": "2022-11-27T01:27:32.723952Z",
     "iopub.status.idle": "2022-11-27T01:27:32.728265Z",
     "shell.execute_reply": "2022-11-27T01:27:32.727346Z"
    },
    "id": "lYX_09FZjzzc",
    "outputId": "6c51419c-5dd3-4b59-c768-1aeb98646b34",
    "papermill": {
     "duration": 0.015258,
     "end_time": "2022-11-27T01:27:32.730198",
     "exception": false,
     "start_time": "2022-11-27T01:27:32.714940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CFG1 = {\n",
    "#     \"model_name\": \"../input/bigbirdrobertalarge/bigbird-roberta-large\",\n",
    "#     \"type\": \"Other Models\",\n",
    "#     \"targets\": ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'],\n",
    "#     \"weights\": \"../input/downloading-ell-bigbird\",\n",
    "#     \"max_length\": 4096,\n",
    "#     \"seed\": 42,\n",
    "#     \"folds\": 4,\n",
    "#     \"lr\": 2e-5, \n",
    "#     \"batch_size\": 1,\n",
    "#     \"num_warmup_steps\": 0.0,\n",
    "#     \"grad_accum\": 1,\n",
    "#     \"pooler\": None,\n",
    "#     \"weight_decay\": 0.3,\n",
    "#     \"grad_norm\": 1000,\n",
    "#     \"dropout\": 0.0,\n",
    "#     \"multisample\": False,\n",
    "#     \"optimizer\": \"AdamW\",\n",
    "#     \"scheduler\": \"linear\",\n",
    "# }\n",
    "# CFG1[\"tokenizer\"] = AutoTokenizer.from_pretrained(CFG1[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5818ea15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:32.747938Z",
     "iopub.status.busy": "2022-11-27T01:27:32.747124Z",
     "iopub.status.idle": "2022-11-27T01:27:32.751728Z",
     "shell.execute_reply": "2022-11-27T01:27:32.750895Z"
    },
    "papermill": {
     "duration": 0.015551,
     "end_time": "2022-11-27T01:27:32.753717",
     "exception": false,
     "start_time": "2022-11-27T01:27:32.738166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CFG2 = {\n",
    "#     \"model_name\": \"../input/debertav3base\",\n",
    "#     \"type\": \"Other Models\",\n",
    "#     \"targets\": ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'],\n",
    "#     \"weights\": \"../input/downloading-ell-debertav3base-notebooks\",\n",
    "#     \"max_length\": 512,\n",
    "#     \"seed\": 42,\n",
    "#     \"folds\": 4,\n",
    "#     \"lr\": 2e-5, \n",
    "#     \"batch_size\": 1,\n",
    "#     \"num_warmup_steps\": 0.0,\n",
    "#     \"grad_accum\": 1,\n",
    "#     \"pooler\": None,\n",
    "#     \"weight_decay\": 0.3,\n",
    "#     \"grad_norm\": 1000,\n",
    "#     \"dropout\": 0.0,\n",
    "#     \"multisample\": False,\n",
    "#     \"optimizer\": \"AdamW\",\n",
    "#     \"scheduler\": \"linear\",\n",
    "# }\n",
    "# CFG2[\"tokenizer\"] = AutoTokenizer.from_pretrained(CFG2[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8bc6f6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:32.771484Z",
     "iopub.status.busy": "2022-11-27T01:27:32.770600Z",
     "iopub.status.idle": "2022-11-27T01:27:32.775634Z",
     "shell.execute_reply": "2022-11-27T01:27:32.774830Z"
    },
    "papermill": {
     "duration": 0.015889,
     "end_time": "2022-11-27T01:27:32.777609",
     "exception": false,
     "start_time": "2022-11-27T01:27:32.761720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CFG3 = {\n",
    "#     \"model_name\": \"../input/deberta-v3-large/deberta-v3-large\",\n",
    "#     \"type\": \"Other Models\",\n",
    "#     \"targets\": ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'],\n",
    "#     \"weights\": \"../input/debertav3large-ell-download\",\n",
    "#     \"max_length\": 512,\n",
    "#     \"seed\": 42,\n",
    "#     \"folds\": 4,\n",
    "#     \"lr\": 2e-5, \n",
    "#     \"batch_size\": 1,\n",
    "#     \"epochs\": 20,\n",
    "#     \"num_warmup_steps\": 0.0,\n",
    "#     \"patience\": 6,\n",
    "#     \"grad_accum\": 1,\n",
    "#     \"pooler\": None,\n",
    "#     \"weight_decay\": 0.3,\n",
    "#     \"grad_norm\": 1000,\n",
    "#     \"dropout\": 0.0,\n",
    "#     \"multisample\": False,\n",
    "#     \"optimizer\": \"AdamW\",\n",
    "#     \"scheduler\": \"linear\",\n",
    "# }\n",
    "# CFG3[\"tokenizer\"] = AutoTokenizer.from_pretrained(CFG3[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b2e9bc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:32.796073Z",
     "iopub.status.busy": "2022-11-27T01:27:32.795292Z",
     "iopub.status.idle": "2022-11-27T01:27:32.800099Z",
     "shell.execute_reply": "2022-11-27T01:27:32.799255Z"
    },
    "papermill": {
     "duration": 0.015895,
     "end_time": "2022-11-27T01:27:32.802003",
     "exception": false,
     "start_time": "2022-11-27T01:27:32.786108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CFG4 = {\n",
    "#     \"model_name\": \"../input/allenailongformerbase4096/longformer\",\n",
    "#     \"type\": \"Full Input\",\n",
    "#     \"targets\": ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'],\n",
    "#     \"weights\": \"../input/downloading-ell-longformer\",\n",
    "#     \"max_length\": 4096,\n",
    "#     \"seed\": 42,\n",
    "#     \"folds\": 4,\n",
    "#     \"lr\": 2e-5, \n",
    "#     \"batch_size\": 1,\n",
    "#     \"epochs\": 32,\n",
    "#     \"num_warmup_steps\": 0.0,\n",
    "#     \"patience\": 6,\n",
    "#     \"grad_accum\": 8,\n",
    "#     \"pooler\": None,\n",
    "#     \"weight_decay\": 0.3,\n",
    "#     \"grad_norm\": 1000,\n",
    "#     \"dropout\": 0.0,\n",
    "#     \"multisample\": False,\n",
    "#     \"optimizer\": \"AdamW\",\n",
    "#     \"scheduler\": \"linear\",\n",
    "# }\n",
    "# CFG4[\"tokenizer\"] = AutoTokenizer.from_pretrained(CFG4[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22fa33b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:32.820155Z",
     "iopub.status.busy": "2022-11-27T01:27:32.819321Z",
     "iopub.status.idle": "2022-11-27T01:27:32.824166Z",
     "shell.execute_reply": "2022-11-27T01:27:32.823347Z"
    },
    "papermill": {
     "duration": 0.015782,
     "end_time": "2022-11-27T01:27:32.826103",
     "exception": false,
     "start_time": "2022-11-27T01:27:32.810321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CFG5 = {\n",
    "#     \"model_name\": \"../input/deberta-v3-large/deberta-v3-large\",\n",
    "#     \"type\": \"Other Models\",\n",
    "#     \"targets\": ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'],\n",
    "#     \"weights\": \"../input/ell-pseudo-download\",\n",
    "#     \"max_length\": 512,\n",
    "#     \"seed\": 42,\n",
    "#     \"folds\": 4,\n",
    "#     \"lr\": 2e-5, \n",
    "#     \"batch_size\": 1,\n",
    "#     \"epochs\": 20,\n",
    "#     \"num_warmup_steps\": 0.0,\n",
    "#     \"patience\": 6,\n",
    "#     \"grad_accum\": 1,\n",
    "#     \"pooler\": None,\n",
    "#     \"weight_decay\": 0.3,\n",
    "#     \"grad_norm\": 1000,\n",
    "#     \"dropout\": 0.0,\n",
    "#     \"multisample\": False,\n",
    "#     \"optimizer\": \"AdamW\",\n",
    "#     \"scheduler\": \"linear\",\n",
    "# }\n",
    "# CFG5[\"tokenizer\"] = AutoTokenizer.from_pretrained(CFG5[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "683960d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:32.844758Z",
     "iopub.status.busy": "2022-11-27T01:27:32.843293Z",
     "iopub.status.idle": "2022-11-27T01:27:32.848302Z",
     "shell.execute_reply": "2022-11-27T01:27:32.847446Z"
    },
    "papermill": {
     "duration": 0.016093,
     "end_time": "2022-11-27T01:27:32.850375",
     "exception": false,
     "start_time": "2022-11-27T01:27:32.834282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CFG6 = {\n",
    "#     \"model_name\": \"../input/debertav3base\",\n",
    "#     \"type\": \"Attention Regression Head\",\n",
    "#     \"targets\": ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'],\n",
    "#     \"weights\": \"../input/downloading-attention-regression-head-debertav3b\",\n",
    "#     \"max_length\": 512,\n",
    "#     \"seed\": 42,\n",
    "#     \"folds\": 4,\n",
    "#     \"lr\": 2e-5, \n",
    "#     \"batch_size\": 16,\n",
    "#     \"epochs\": 20,\n",
    "#     \"num_warmup_steps\": 0.0,\n",
    "#     \"patience\": 6,\n",
    "#     \"grad_accum\": 1,\n",
    "#     \"pooler\": \"attention\",\n",
    "#     \"layer_start\": 1,\n",
    "#     \"weight_decay\": 0.3,\n",
    "#     \"grad_norm\": 1000,\n",
    "#     \"hidden_dim\": 128,\n",
    "#     \"dropout\": 0.0,\n",
    "#     \"multisample\": False,\n",
    "#     \"optimizer\": \"AdamW\",\n",
    "#     \"scheduler\": \"linear\",\n",
    "# }\n",
    "# CFG6[\"tokenizer\"] = AutoTokenizer.from_pretrained(CFG6[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4c49b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:32.868466Z",
     "iopub.status.busy": "2022-11-27T01:27:32.867721Z",
     "iopub.status.idle": "2022-11-27T01:27:32.872593Z",
     "shell.execute_reply": "2022-11-27T01:27:32.871788Z"
    },
    "papermill": {
     "duration": 0.015884,
     "end_time": "2022-11-27T01:27:32.874555",
     "exception": false,
     "start_time": "2022-11-27T01:27:32.858671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CFG7 = {\n",
    "#     \"model_name\": \"../input/debertav3base\",\n",
    "#     \"type\": \"Weighted Regression Head\",\n",
    "#     \"targets\": ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'],\n",
    "#     \"weights\": \"../input/downloading-weighted-head-debertav3base\",\n",
    "#     \"max_length\": 512,\n",
    "#     \"seed\": 42,\n",
    "#     \"folds\": 4,\n",
    "#     \"lr\": 2e-5, \n",
    "#     \"batch_size\": 16,\n",
    "#     \"epochs\": 20,\n",
    "#     \"num_warmup_steps\": 0.0,\n",
    "#     \"patience\": 6,\n",
    "#     \"grad_accum\": 1,\n",
    "#     \"pooler\": \"weighted\",\n",
    "#     \"layer_start\": 9,\n",
    "#     \"weight_decay\": 0.3,\n",
    "#     \"grad_norm\": 1000,\n",
    "#     \"dropout\": 0.0,\n",
    "#     \"multisample\": False,\n",
    "#     \"optimizer\": \"AdamW\",\n",
    "#     \"scheduler\": \"linear\",\n",
    "# }\n",
    "# CFG7[\"tokenizer\"] = AutoTokenizer.from_pretrained(CFG7[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83c65247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:32.892290Z",
     "iopub.status.busy": "2022-11-27T01:27:32.892023Z",
     "iopub.status.idle": "2022-11-27T01:27:32.896316Z",
     "shell.execute_reply": "2022-11-27T01:27:32.895424Z"
    },
    "papermill": {
     "duration": 0.015519,
     "end_time": "2022-11-27T01:27:32.898348",
     "exception": false,
     "start_time": "2022-11-27T01:27:32.882829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CFG8 = {\n",
    "#     \"model_name\": \"../input/debertav3base\",\n",
    "#     \"type\": \"Attention Regression Head + Multisample Dropout\",\n",
    "#     \"targets\": ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'],\n",
    "#     \"weights\": \"../input/downloading-attention-multisample-debertav3base\",\n",
    "#     \"max_length\": 512,\n",
    "#     \"seed\": 42,\n",
    "#     \"folds\": 4,\n",
    "#     \"lr\": 2e-5, \n",
    "#     \"batch_size\": 16,\n",
    "#     \"epochs\": 20,\n",
    "#     \"num_warmup_steps\": 0.0,\n",
    "#     \"patience\": 6,\n",
    "#     \"grad_accum\": 1,\n",
    "#     \"pooler\": \"attention\",\n",
    "#     \"layer_start\": 1,\n",
    "#     \"weight_decay\": 0.3,\n",
    "#     \"grad_norm\": 1000,\n",
    "#     \"hidden_dim\": 128,\n",
    "#     \"dropout\": 0.3,\n",
    "#     \"multisample\": True,\n",
    "#     \"optimizer\": \"AdamW\",\n",
    "#     \"scheduler\": \"linear\",\n",
    "# }\n",
    "# CFG8[\"tokenizer\"] = AutoTokenizer.from_pretrained(CFG8[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d68a24de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:32.915966Z",
     "iopub.status.busy": "2022-11-27T01:27:32.915701Z",
     "iopub.status.idle": "2022-11-27T01:27:32.920257Z",
     "shell.execute_reply": "2022-11-27T01:27:32.919306Z"
    },
    "papermill": {
     "duration": 0.015764,
     "end_time": "2022-11-27T01:27:32.922346",
     "exception": false,
     "start_time": "2022-11-27T01:27:32.906582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CFG9 = {\n",
    "#     \"model_name\": \"../input/deberta-v3-large/deberta-v3-large\",\n",
    "#     \"type\": \"DS All\",\n",
    "#     \"targets\": ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'],\n",
    "#     \"weights\": \"../input/downloading-debertav3large-l1-ds-all\", \n",
    "#     \"max_length\": 512,\n",
    "#     \"seed\": 42,\n",
    "#     \"folds\": 4,\n",
    "#     \"lr\": 2e-5, \n",
    "#     \"batch_size\": 4,\n",
    "#     \"epochs\": 20,\n",
    "#     \"num_warmup_steps\": 0.0,\n",
    "#     \"patience\": 6,\n",
    "#     \"grad_accum\": 4,\n",
    "#     \"pooler\": \"DS All\",\n",
    "#     \"layer_start\": 9,\n",
    "#     \"weight_decay\": 0.3,\n",
    "#     \"grad_norm\": 1000,\n",
    "#     \"aux_weight\": 0.5,\n",
    "#     \"dropout\": 0.1,\n",
    "#     \"oof_path\": \"deberta-v3-large-L1.csv\", \n",
    "#     \"multisample\": False,\n",
    "#     \"optimizer\": \"AdamW\",\n",
    "#     \"scheduler\": \"linear\",\n",
    "# }\n",
    "# CFG9[\"tokenizer\"] = AutoTokenizer.from_pretrained(CFG9[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26361468",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:32.940094Z",
     "iopub.status.busy": "2022-11-27T01:27:32.939826Z",
     "iopub.status.idle": "2022-11-27T01:27:34.031658Z",
     "shell.execute_reply": "2022-11-27T01:27:34.030627Z"
    },
    "papermill": {
     "duration": 1.103388,
     "end_time": "2022-11-27T01:27:34.034094",
     "exception": false,
     "start_time": "2022-11-27T01:27:32.930706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:447: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "CFG14 = {\n",
    "    \"model_name\": \"../input/deberta-v3-large/deberta-v3-large\",\n",
    "    \"type\": \"DS Last\",\n",
    "    \"targets\": ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'],\n",
    "    \"weights\": \"/kaggle/input/downloading-debertav3large-l1-ds-last\",\n",
    "    \"max_length\": 512,\n",
    "    \"seed\": 42,\n",
    "    \"folds\": 4,\n",
    "    \"lr\": 2e-5, \n",
    "    \"batch_size\": 4,\n",
    "    \"epochs\": 20,\n",
    "    \"num_warmup_steps\": 0.0,\n",
    "    \"patience\": 6,\n",
    "    \"grad_accum\": 4,\n",
    "    \"pooler\": \"DS Last\",\n",
    "    \"layer_start\": 9,\n",
    "    \"weight_decay\": 0.3,\n",
    "    \"grad_norm\": 1000,\n",
    "    \"aux_weight\": 0.5,\n",
    "    \"dropout\": 0.1,\n",
    "    \"multisample\": False,\n",
    "    \"oof_path\": \"deberta-v3-large-L1-DS-Last.csv\", \n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"scheduler\": \"linear\",\n",
    "}\n",
    "CFG14[\"tokenizer\"] = AutoTokenizer.from_pretrained(CFG14[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37b55680",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:34.053323Z",
     "iopub.status.busy": "2022-11-27T01:27:34.052787Z",
     "iopub.status.idle": "2022-11-27T01:27:34.099901Z",
     "shell.execute_reply": "2022-11-27T01:27:34.098906Z"
    },
    "papermill": {
     "duration": 0.059324,
     "end_time": "2022-11-27T01:27:34.102376",
     "exception": false,
     "start_time": "2022-11-27T01:27:34.043052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG13 = {\n",
    "    \"model_name\": \"/kaggle/input/ernie20largeen/nghuyong/ernie-2.0-large-en\",\n",
    "    \"type\": \"Other Models\",\n",
    "    \"targets\": ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'],\n",
    "    \"weights\": \"/kaggle/input/downloading-ernie-2-0-large\",\n",
    "    \"max_length\": 512,\n",
    "    \"seed\": 42,\n",
    "    \"folds\": 4,\n",
    "    \"lr\": 2e-5, \n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 20,\n",
    "    \"num_warmup_steps\": 0.0,\n",
    "    \"patience\": 6,\n",
    "    \"grad_accum\": 1,\n",
    "    \"pooler\": None,\n",
    "    \"weight_decay\": 0.3,\n",
    "    \"grad_norm\": 1000,\n",
    "    \"multisample\": False,\n",
    "    \"dropout\": 0.0,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"scheduler\": \"linear\",\n",
    "}\n",
    "CFG13[\"tokenizer\"] = AutoTokenizer.from_pretrained(CFG13[\"model_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbca33d",
   "metadata": {
    "id": "ekR23mjnezO7",
    "papermill": {
     "duration": 0.008497,
     "end_time": "2022-11-27T01:27:34.119727",
     "exception": false,
     "start_time": "2022-11-27T01:27:34.111230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f25dde01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:34.138806Z",
     "iopub.status.busy": "2022-11-27T01:27:34.137909Z",
     "iopub.status.idle": "2022-11-27T01:27:34.142673Z",
     "shell.execute_reply": "2022-11-27T01:27:34.141809Z"
    },
    "papermill": {
     "duration": 0.016212,
     "end_time": "2022-11-27T01:27:34.144600",
     "exception": false,
     "start_time": "2022-11-27T01:27:34.128388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CFGS = [CFG1, CFG2, CFG3, CFG5, CFG6, CFG7, CFG8]\n",
    "CFGS = [CFG13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9bc2b08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:34.163217Z",
     "iopub.status.busy": "2022-11-27T01:27:34.162335Z",
     "iopub.status.idle": "2022-11-27T01:27:34.169867Z",
     "shell.execute_reply": "2022-11-27T01:27:34.169019Z"
    },
    "papermill": {
     "duration": 0.018719,
     "end_time": "2022-11-27T01:27:34.171790",
     "exception": false,
     "start_time": "2022-11-27T01:27:34.153071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WeightedLayerPooling(torch.nn.Module):\n",
    "    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n",
    "        super(WeightedLayerPooling, self).__init__()\n",
    "        self.layer_start = layer_start\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.layer_weights = layer_weights if layer_weights is not None \\\n",
    "            else nn.Parameter(\n",
    "                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)\n",
    "            )\n",
    "\n",
    "    def forward(self, all_hidden_states):\n",
    "        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n",
    "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
    "        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n",
    "        return weighted_average\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdd118e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:34.190197Z",
     "iopub.status.busy": "2022-11-27T01:27:34.189430Z",
     "iopub.status.idle": "2022-11-27T01:27:34.196064Z",
     "shell.execute_reply": "2022-11-27T01:27:34.195205Z"
    },
    "papermill": {
     "duration": 0.017799,
     "end_time": "2022-11-27T01:27:34.198023",
     "exception": false,
     "start_time": "2022-11-27T01:27:34.180224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.W = nn.Linear(in_features, hidden_dim)\n",
    "        self.V = nn.Linear(hidden_dim, 1)\n",
    "        self.out_features = hidden_dim\n",
    "\n",
    "    def forward(self, features):\n",
    "        att = torch.tanh(self.W(features))\n",
    "        score = self.V(att)\n",
    "        attention_weights = torch.softmax(score, dim=0)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = torch.sum(context_vector, dim=0)\n",
    "\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a525b4ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:34.216563Z",
     "iopub.status.busy": "2022-11-27T01:27:34.216305Z",
     "iopub.status.idle": "2022-11-27T01:27:34.243684Z",
     "shell.execute_reply": "2022-11-27T01:27:34.242861Z"
    },
    "id": "EIj0e07d8crC",
    "papermill": {
     "duration": 0.038978,
     "end_time": "2022-11-27T01:27:34.245611",
     "exception": false,
     "start_time": "2022-11-27T01:27:34.206633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#OBVIOUSLY, CHANGE THIS AS YOU NEED. USE SELF.LOG FOR ALL IMPORTANT METRICS\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, config, vocab_length, data_loader_len):\n",
    "        super(Model, self).__init__()\n",
    "        self.config = config\n",
    "        self.vocab_length = vocab_length\n",
    "        self.base_model = AutoModel.from_pretrained(self.config['model_name'], output_hidden_states = True)  \n",
    "        self.base_model.resize_token_embeddings(vocab_length)\n",
    "        self.dropout = torch.nn.Dropout(p=CFG[\"dropout\"])\n",
    "        self.order = torch.LongTensor([5, 0, 1, 2, 3, 4]).cuda()\n",
    "        \n",
    "        if self.config[\"pooler\"] == \"weighted\":\n",
    "            self.pooler = WeightedLayerPooling(self.base_model.config.num_hidden_layers, layer_start = self.config[\"layer_start\"])  \n",
    "            self._init_weights(self.pooler.layer_weights)\n",
    "            \n",
    "        elif self.config[\"pooler\"] == \"attention\":\n",
    "            self.pooler = AttentionPooling(self.base_model.config.hidden_size, config[\"hidden_dim\"])\n",
    "\n",
    "        if self.config[\"multisample\"]:\n",
    "            self.dropout1 = nn.Dropout(0.1)\n",
    "            self.dropout2 = nn.Dropout(0.2)\n",
    "            self.dropout3 = nn.Dropout(0.3)\n",
    "            self.dropout4 = nn.Dropout(0.4)\n",
    "            self.dropout5 = nn.Dropout(0.5)\n",
    "            \n",
    "        self.dropout = nn.Dropout(self.config[\"dropout\"])\n",
    "        self.fc = nn.Linear(self.base_model.config.hidden_size, 6)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "        if config[\"pooler\"] == \"DS All\" or config[\"pooler\"] == \"DS MaxPool\":\n",
    "            self.fcs = nn.ModuleList([])\n",
    "            for _ in range(6):\n",
    "                layer = nn.Linear(self.base_model.config.hidden_size, 1)\n",
    "                self._init_weights(layer)\n",
    "                self.fcs.append(layer)\n",
    "        else:\n",
    "            self.fcs = nn.ModuleList([])\n",
    "            for _ in range(7):\n",
    "                layer = nn.Linear(self.base_model.config.hidden_size, 1)\n",
    "                self._init_weights(layer)\n",
    "                self.fcs.append(layer)\n",
    "        \n",
    "        self.data_loader_len = data_loader_len\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.base_model.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.base_model.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def feature(self, inputs):\n",
    "\n",
    "        if self.config[\"pooler\"] == \"weighted\":\n",
    "            input_ids, attention_mask = inputs[\"input_ids\"], inputs[\"attention_mask\"]\n",
    "        \n",
    "            x = self.base_model(input_ids = input_ids, attention_mask = attention_mask)[\"hidden_states\"]\n",
    "\n",
    "            x = torch.stack(x)\n",
    "            cls_embeddings = self.pooler(x)[:, 0]\n",
    "\n",
    "            return cls_embeddings\n",
    "        \n",
    "        \n",
    "        elif self.config[\"pooler\"] == \"DS Last\":\n",
    "            input_ids, attention_mask = inputs[\"input_ids\"], inputs[\"attention_mask\"]\n",
    "        \n",
    "            x = self.base_model(input_ids = input_ids, attention_mask = attention_mask)[\"hidden_states\"]\n",
    "\n",
    "            x = torch.stack(x)\n",
    "\n",
    "            # Last 6 layers\n",
    "            return x[-7:, :, :, :]\n",
    "        \n",
    "        elif self.config[\"pooler\"] == \"DS All\":\n",
    "            input_ids, attention_mask = inputs[\"input_ids\"], inputs[\"attention_mask\"]\n",
    "        \n",
    "            x = self.base_model(input_ids = input_ids, attention_mask = attention_mask)[\"hidden_states\"]\n",
    "\n",
    "            x = torch.stack(x)\n",
    "\n",
    "            # Last 6 layers\n",
    "            return x[-6:, :, :, :]\n",
    "        \n",
    "        elif self.config[\"pooler\"] == \"DS MaxPool\":\n",
    "            input_ids, attention_mask = inputs[\"input_ids\"], inputs[\"attention_mask\"]\n",
    "        \n",
    "            x = self.base_model(input_ids = input_ids, attention_mask = attention_mask)[\"hidden_states\"]\n",
    "\n",
    "            x = torch.stack(x)\n",
    "\n",
    "            # Last 6 layers\n",
    "            return x[-6:, :, :, :]\n",
    "            \n",
    "        else:\n",
    "            input_ids, attention_mask = inputs[\"input_ids\"], inputs[\"attention_mask\"]\n",
    "        \n",
    "            x = self.base_model(input_ids = input_ids, attention_mask = attention_mask)[\"last_hidden_state\"]\n",
    "\n",
    "            return x[:, 0, :]\n",
    "\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        features = self.feature(inputs)\n",
    "        \n",
    "        if self.config[\"multisample\"]:\n",
    "            logits1 = self.fc(self.dropout1(features))\n",
    "            logits2 = self.fc(self.dropout2(features))\n",
    "            logits3 = self.fc(self.dropout3(features))\n",
    "            logits4 = self.fc(self.dropout4(features))\n",
    "            logits5 = self.fc(self.dropout5(features))\n",
    "\n",
    "            logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n",
    "            \n",
    "            return logits\n",
    "\n",
    "            \n",
    "        if self.config[\"pooler\"] == \"DS Last\":\n",
    "\n",
    "            outputs = []\n",
    "\n",
    "            for layer_num, layer in enumerate(features):\n",
    "\n",
    "                if layer_num == (len(features) - 1):\n",
    "                    pred = self.fc(self.dropout(layer[:, 0, :]))\n",
    "                    break\n",
    "            \n",
    "                outputs.append(self.fcs[layer_num](self.dropout(layer[:, 0, :])))\n",
    "\n",
    "            outputs = torch.stack(outputs)\n",
    "            \n",
    "            return pred\n",
    "        \n",
    "        elif self.config[\"pooler\"] == \"DS MaxPool\":\n",
    "\n",
    "            outputs = []\n",
    "\n",
    "            layers = []\n",
    "\n",
    "            for layer_num, layer in enumerate(features):\n",
    "                \n",
    "                layers.append(self.dropout(layer[:, 0, :]))\n",
    "                \n",
    "                outputs.append(self.fcs[layer_num](layers[-1]))\n",
    "\n",
    "            outputs = torch.stack(outputs)\n",
    "\n",
    "            layers = torch.stack(layers)\n",
    "\n",
    "            final_cls = torch.max(layers, dim = 0)[0]\n",
    "\n",
    "            pred = checkpoint(self.fc, final_cls)\n",
    "            \n",
    "            return pred\n",
    "        \n",
    "        elif self.config[\"pooler\"] == \"DS All\":\n",
    "\n",
    "            outputs = []\n",
    "\n",
    "            layers = []\n",
    "\n",
    "            for layer_num, layer in enumerate(features):\n",
    "                \n",
    "                layers.append(self.dropout(layer[:, 0, :]))\n",
    "                \n",
    "                outputs.append(self.fcs[layer_num](layers[-1]))\n",
    "            \n",
    "            outputs = torch.stack(outputs)\n",
    "\n",
    "            return torch.index_select(outputs.squeeze(-1).transpose(0,1), 1, self.order)\n",
    "        \n",
    "        else:\n",
    "            logits = self.fc(features)\n",
    "            \n",
    "            return logits\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1601965c",
   "metadata": {
    "id": "kPPDgVLsjzzd",
    "papermill": {
     "duration": 0.0083,
     "end_time": "2022-11-27T01:27:34.263080",
     "exception": false,
     "start_time": "2022-11-27T01:27:34.254780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2604de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:34.281594Z",
     "iopub.status.busy": "2022-11-27T01:27:34.281309Z",
     "iopub.status.idle": "2022-11-27T01:27:34.293748Z",
     "shell.execute_reply": "2022-11-27T01:27:34.292875Z"
    },
    "id": "sTadJIpv1LGs",
    "papermill": {
     "duration": 0.024175,
     "end_time": "2022-11-27T01:27:34.295755",
     "exception": false,
     "start_time": "2022-11-27T01:27:34.271580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestData(Dataset):\n",
    "    def __init__(self, df, config, base_path, special_tokens = None):\n",
    "        self.df = df\n",
    "        self.esc_chars = ['\\\"', \"\\\\\", \"\\n\", \"\\r\", \"\\t\", \"\\b\", \"\\f\", \"\\v\", \":)\", \";)\", \":(\", \"uwu\", \"owo\", \"xd\", \":3\", \":-)\", \":D\", \">:(\", \"\\xa0\", \"\\x92\", \"\\x93\", \"\\x91\", \"\\x94\", \"\\x97\", \"x\\B4\", \"\\x96\", \"\\x82\", \"\\x84\"]\n",
    "        self.df[\"full_text\"] = self.df[\"full_text\"].apply(lambda text: self.resolve_encodings_and_normalize(text))\n",
    "\n",
    "        codecs.register_error(\"replace_encoding_with_utf8\", self.replace_encoding_with_utf8)\n",
    "        codecs.register_error(\"replace_decoding_with_cp1252\", self.replace_decoding_with_cp1252)\n",
    "\n",
    "    def replace_encoding_with_utf8(self, error):\n",
    "        return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n",
    "\n",
    "\n",
    "    def replace_decoding_with_cp1252(self, error):\n",
    "        return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n",
    "\n",
    "\n",
    "    def resolve_encodings_and_normalize(self, text: str) -> str:\n",
    "        text = (\n",
    "            text.encode(\"raw_unicode_escape\")\n",
    "            .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "            .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n",
    "            .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "        )\n",
    "        \n",
    "        text = unidecode(text)\n",
    "        \n",
    "        return self.remove_esc_chars(text)\n",
    "\n",
    "    def remove_esc_chars(self, text):\n",
    "        txt = deepcopy(text)\n",
    "        for char in self.esc_chars:\n",
    "            if char == '\\\"':\n",
    "                txt = txt.replace(char, '\"')\n",
    "            elif char == \"\\x92\" or char == \"\\x91\" or char == \"\\xB4\":\n",
    "                txt = txt.replace(char, \"'\")\n",
    "            elif char == \"\\0x93\" or char == \"\\0x94\":\n",
    "                txt = txt.replace(char, '\"')\n",
    "            elif char == \"\\0x97\" or char == \"\\0x96\":\n",
    "                txt = txt.replace(char, '-')\n",
    "            elif char == \"\\0x82\" or char == \"\\0x84\":\n",
    "                txt = txt.replace(char, ',')\n",
    "            else:\n",
    "                txt = txt.replace(char, ' ')\n",
    "        return txt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.df.iloc[idx][\"full_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8394bf6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:34.314504Z",
     "iopub.status.busy": "2022-11-27T01:27:34.313668Z",
     "iopub.status.idle": "2022-11-27T01:27:34.319319Z",
     "shell.execute_reply": "2022-11-27T01:27:34.318476Z"
    },
    "id": "WwuADIRbwAqs",
    "papermill": {
     "duration": 0.016974,
     "end_time": "2022-11-27T01:27:34.321306",
     "exception": false,
     "start_time": "2022-11-27T01:27:34.304332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def construct_collate_fn(config):\n",
    "    def collate_dynamic_padding(batch):\n",
    "        # Dynamic Padding tokenization\n",
    "        sentences = config[\"tokenizer\"](batch, padding=True, max_length = config[\"max_length\"], truncation = True, return_token_type_ids = False, return_tensors=\"pt\")\n",
    "        return sentences\n",
    "    \n",
    "    return collate_dynamic_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf703d66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:34.339915Z",
     "iopub.status.busy": "2022-11-27T01:27:34.339146Z",
     "iopub.status.idle": "2022-11-27T01:27:34.344701Z",
     "shell.execute_reply": "2022-11-27T01:27:34.343767Z"
    },
    "id": "4lREk9P6jzzg",
    "papermill": {
     "duration": 0.016949,
     "end_time": "2022-11-27T01:27:34.346799",
     "exception": false,
     "start_time": "2022-11-27T01:27:34.329850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CHANGE AS NEEDED. MOST OF THE TIME, PYTORCH'S DEFAULT COLLATOR IS ENOUGH.\n",
    "class DataModule():\n",
    "    def __init__(self, config, test, collate_fn):\n",
    "        self.config = config\n",
    "        self.test = test\n",
    "        self.collate_fn = collate_fn\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_loader = DataLoader(self.test, batch_size = self.config[\"batch_size\"], collate_fn = self.collate_fn)      \n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59df734",
   "metadata": {
    "id": "L8HsBZmivxSj",
    "papermill": {
     "duration": 0.008284,
     "end_time": "2022-11-27T01:27:34.363901",
     "exception": false,
     "start_time": "2022-11-27T01:27:34.355617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faabbdbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:34.383635Z",
     "iopub.status.busy": "2022-11-27T01:27:34.382011Z",
     "iopub.status.idle": "2022-11-27T01:27:34.388542Z",
     "shell.execute_reply": "2022-11-27T01:27:34.387686Z"
    },
    "papermill": {
     "duration": 0.017909,
     "end_time": "2022-11-27T01:27:34.390530",
     "exception": false,
     "start_time": "2022-11-27T01:27:34.372621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    outputs = []\n",
    "    device = torch.device('cuda')\n",
    "    model = model.to(device).eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(loader):\n",
    "            for key, value in inputs.items():\n",
    "                inputs[key] = value.to(device)\n",
    "            predictions = model(inputs)\n",
    "            outputs.append(predictions)\n",
    "    return torch.cat(tuple(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "081daf20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:34.409260Z",
     "iopub.status.busy": "2022-11-27T01:27:34.408372Z",
     "iopub.status.idle": "2022-11-27T01:27:34.415014Z",
     "shell.execute_reply": "2022-11-27T01:27:34.414174Z"
    },
    "papermill": {
     "duration": 0.017875,
     "end_time": "2022-11-27T01:27:34.416982",
     "exception": false,
     "start_time": "2022-11-27T01:27:34.399107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_predictions(loader, num_preds, path, config):\n",
    "    outputs = []\n",
    "    for fold in range(num_preds):\n",
    "\n",
    "        model = Model(config, len(config[\"tokenizer\"]), len(loader))\n",
    "        checkpoint = torch.load(f\"{path}/fold-{fold}.pt\", map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "        outputs.append(predict(model, loader))\n",
    "        \n",
    "        del model, checkpoint; gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    return torch.stack(tuple(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f50f1e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:27:34.435469Z",
     "iopub.status.busy": "2022-11-27T01:27:34.434717Z",
     "iopub.status.idle": "2022-11-27T01:30:13.610208Z",
     "shell.execute_reply": "2022-11-27T01:30:13.608597Z"
    },
    "papermill": {
     "duration": 159.188778,
     "end_time": "2022-11-27T01:30:13.614186",
     "exception": false,
     "start_time": "2022-11-27T01:27:34.425408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 30.07it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "for CFG in CFGS:\n",
    "    test = TestData(pd.read_csv(\"../input/feedback-prize-english-language-learning/test.csv\"), CFG, \"./\")\n",
    "\n",
    "    dataset = DataModule(CFG, test, construct_collate_fn(CFG))\n",
    "\n",
    "    test_loader = dataset.test_dataloader()\n",
    "    \n",
    "    outputs = get_predictions(test_loader, num_preds = 4, path=CFG[\"weights\"], config = CFG)\n",
    "    \n",
    "    all_preds.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a2136d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:30:13.654999Z",
     "iopub.status.busy": "2022-11-27T01:30:13.654340Z",
     "iopub.status.idle": "2022-11-27T01:30:13.661197Z",
     "shell.execute_reply": "2022-11-27T01:30:13.660143Z"
    },
    "papermill": {
     "duration": 0.02376,
     "end_time": "2022-11-27T01:30:13.663377",
     "exception": false,
     "start_time": "2022-11-27T01:30:13.639617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2246f400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:30:13.683624Z",
     "iopub.status.busy": "2022-11-27T01:30:13.683328Z",
     "iopub.status.idle": "2022-11-27T01:30:13.720641Z",
     "shell.execute_reply": "2022-11-27T01:30:13.719622Z"
    },
    "papermill": {
     "duration": 0.049912,
     "end_time": "2022-11-27T01:30:13.722799",
     "exception": false,
     "start_time": "2022-11-27T01:30:13.672887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[2.8320, 2.6279, 2.9077, 2.9311, 2.6271, 2.7072],\n",
       "          [2.7152, 2.4567, 2.6243, 2.5590, 2.0677, 2.6769],\n",
       "          [3.6321, 3.3606, 3.5519, 3.6467, 3.5881, 3.5491]],\n",
       " \n",
       "         [[2.7915, 2.5918, 3.0143, 2.9139, 2.6483, 2.6162],\n",
       "          [2.7407, 2.4680, 2.7743, 2.5778, 2.4082, 2.7162],\n",
       "          [3.6322, 3.3006, 3.4676, 3.5488, 3.2469, 3.3507]],\n",
       " \n",
       "         [[2.6924, 2.7878, 3.1450, 3.0423, 2.6908, 2.6850],\n",
       "          [2.7947, 2.7697, 2.8286, 2.6390, 2.2946, 2.8212],\n",
       "          [3.6556, 3.5074, 3.6025, 3.6201, 3.3463, 3.3978]],\n",
       " \n",
       "         [[2.9577, 2.9801, 3.1688, 3.1578, 2.7648, 2.8780],\n",
       "          [2.6192, 2.5910, 2.7561, 2.4139, 2.1595, 2.7531],\n",
       "          [4.0686, 3.8909, 3.9064, 4.1088, 3.7099, 3.9025]]], device='cuda:0')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08eb8710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:30:13.742876Z",
     "iopub.status.busy": "2022-11-27T01:30:13.742551Z",
     "iopub.status.idle": "2022-11-27T01:30:13.749423Z",
     "shell.execute_reply": "2022-11-27T01:30:13.748563Z"
    },
    "papermill": {
     "duration": 0.019133,
     "end_time": "2022-11-27T01:30:13.751399",
     "exception": false,
     "start_time": "2022-11-27T01:30:13.732266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for num, pred in enumerate(all_preds):\n",
    "    preds.append(torch.mean(pred, dim = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b427e649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:30:13.771297Z",
     "iopub.status.busy": "2022-11-27T01:30:13.771005Z",
     "iopub.status.idle": "2022-11-27T01:30:13.777216Z",
     "shell.execute_reply": "2022-11-27T01:30:13.776379Z"
    },
    "papermill": {
     "duration": 0.018361,
     "end_time": "2022-11-27T01:30:13.779133",
     "exception": false,
     "start_time": "2022-11-27T01:30:13.760772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_preds = torch.mean(torch.stack(preds), dim = 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "682b7821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:30:13.798752Z",
     "iopub.status.busy": "2022-11-27T01:30:13.798454Z",
     "iopub.status.idle": "2022-11-27T01:30:13.804624Z",
     "shell.execute_reply": "2022-11-27T01:30:13.803689Z"
    },
    "papermill": {
     "duration": 0.018476,
     "end_time": "2022-11-27T01:30:13.806780",
     "exception": false,
     "start_time": "2022-11-27T01:30:13.788304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.8184164, 2.7469065, 3.0589442, 3.011283 , 2.6827464, 2.7216218],\n",
       "       [2.7174506, 2.5713854, 2.7458014, 2.5474372, 2.2324948, 2.7418466],\n",
       "       [3.7471223, 3.5148609, 3.6321054, 3.7310827, 3.4727864, 3.5500383]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a094bfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:30:13.827308Z",
     "iopub.status.busy": "2022-11-27T01:30:13.826519Z",
     "iopub.status.idle": "2022-11-27T01:30:13.830959Z",
     "shell.execute_reply": "2022-11-27T01:30:13.830057Z"
    },
    "papermill": {
     "duration": 0.016835,
     "end_time": "2022-11-27T01:30:13.833001",
     "exception": false,
     "start_time": "2022-11-27T01:30:13.816166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ONLY FOR ONE CONFIGURATION\n",
    "# final_preds = np.vstack(all_preds)\n",
    "# final_preds = torch.stack(all_preds)\n",
    "# final_preds = torch.mean(torch.squeeze(torch.stack(all_preds)), dim = 0).cpu().numpy()\n",
    "\n",
    "# ONLY FOR MULTIPLE CONFIGURATIONS\n",
    "# final_preds = torch.mean(torch.mean(torch.squeeze(torch.stack(all_preds)), dim = 0), dim = 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2310ad64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:30:13.852902Z",
     "iopub.status.busy": "2022-11-27T01:30:13.852597Z",
     "iopub.status.idle": "2022-11-27T01:30:13.859564Z",
     "shell.execute_reply": "2022-11-27T01:30:13.858636Z"
    },
    "papermill": {
     "duration": 0.019212,
     "end_time": "2022-11-27T01:30:13.861528",
     "exception": false,
     "start_time": "2022-11-27T01:30:13.842316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fa342ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:30:13.881479Z",
     "iopub.status.busy": "2022-11-27T01:30:13.881209Z",
     "iopub.status.idle": "2022-11-27T01:30:13.887538Z",
     "shell.execute_reply": "2022-11-27T01:30:13.886536Z"
    },
    "papermill": {
     "duration": 0.019661,
     "end_time": "2022-11-27T01:30:13.890618",
     "exception": false,
     "start_time": "2022-11-27T01:30:13.870957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.8184164, 2.7469065, 3.0589442, 3.011283 , 2.6827464, 2.7216218],\n",
       "       [2.7174506, 2.5713854, 2.7458014, 2.5474372, 2.2324948, 2.7418466],\n",
       "       [3.7471223, 3.5148609, 3.6321054, 3.7310827, 3.4727864, 3.5500383]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7252e3cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:30:13.911267Z",
     "iopub.status.busy": "2022-11-27T01:30:13.910807Z",
     "iopub.status.idle": "2022-11-27T01:30:13.926778Z",
     "shell.execute_reply": "2022-11-27T01:30:13.925939Z"
    },
    "papermill": {
     "duration": 0.028285,
     "end_time": "2022-11-27T01:30:13.928694",
     "exception": false,
     "start_time": "2022-11-27T01:30:13.900409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = pd.read_csv(\"../input/feedback-prize-english-language-learning/test.csv\")\n",
    "submission = pd.DataFrame({\"text_id\": t.text_id})\n",
    "del t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dccba99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:30:13.949056Z",
     "iopub.status.busy": "2022-11-27T01:30:13.948790Z",
     "iopub.status.idle": "2022-11-27T01:30:13.957195Z",
     "shell.execute_reply": "2022-11-27T01:30:13.956134Z"
    },
    "papermill": {
     "duration": 0.021219,
     "end_time": "2022-11-27T01:30:13.959571",
     "exception": false,
     "start_time": "2022-11-27T01:30:13.938352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission[\"cohesion\"], submission[\"syntax\"], submission[\"vocabulary\"], submission[\"phraseology\"], submission[\"grammar\"], submission[\"conventions\"] = final_preds[:,0], final_preds[:,1], final_preds[:,2], final_preds[:,3], final_preds[:,4], final_preds[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6d5ae6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:30:13.979911Z",
     "iopub.status.busy": "2022-11-27T01:30:13.979602Z",
     "iopub.status.idle": "2022-11-27T01:30:13.989965Z",
     "shell.execute_reply": "2022-11-27T01:30:13.989136Z"
    },
    "papermill": {
     "duration": 0.022859,
     "end_time": "2022-11-27T01:30:13.991997",
     "exception": false,
     "start_time": "2022-11-27T01:30:13.969138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32aed5b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T01:30:14.012338Z",
     "iopub.status.busy": "2022-11-27T01:30:14.012058Z",
     "iopub.status.idle": "2022-11-27T01:30:14.027806Z",
     "shell.execute_reply": "2022-11-27T01:30:14.026779Z"
    },
    "papermill": {
     "duration": 0.028447,
     "end_time": "2022-11-27T01:30:14.030054",
     "exception": false,
     "start_time": "2022-11-27T01:30:14.001607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>2.818416</td>\n",
       "      <td>2.746907</td>\n",
       "      <td>3.058944</td>\n",
       "      <td>3.011283</td>\n",
       "      <td>2.682746</td>\n",
       "      <td>2.721622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2.717451</td>\n",
       "      <td>2.571385</td>\n",
       "      <td>2.745801</td>\n",
       "      <td>2.547437</td>\n",
       "      <td>2.232495</td>\n",
       "      <td>2.741847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.747122</td>\n",
       "      <td>3.514861</td>\n",
       "      <td>3.632105</td>\n",
       "      <td>3.731083</td>\n",
       "      <td>3.472786</td>\n",
       "      <td>3.550038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "0  0000C359D63E  2.818416  2.746907    3.058944     3.011283  2.682746   \n",
       "1  000BAD50D026  2.717451  2.571385    2.745801     2.547437  2.232495   \n",
       "2  00367BB2546B  3.747122  3.514861    3.632105     3.731083  3.472786   \n",
       "\n",
       "   conventions  \n",
       "0     2.721622  \n",
       "1     2.741847  \n",
       "2     3.550038  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef11ea5",
   "metadata": {
    "papermill": {
     "duration": 0.009693,
     "end_time": "2022-11-27T01:30:14.049981",
     "exception": false,
     "start_time": "2022-11-27T01:30:14.040288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dd6541",
   "metadata": {
    "papermill": {
     "duration": 0.009606,
     "end_time": "2022-11-27T01:30:14.069836",
     "exception": false,
     "start_time": "2022-11-27T01:30:14.060230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 188.364451,
   "end_time": "2022-11-27T01:30:17.329424",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-27T01:27:08.964973",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
